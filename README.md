Sign Language Real-Time Interpreter ğŸ¤ŸğŸ“·
This project is a real-time Sign Language Interpreter that uses MediaPipe, OpenCV, and TensorFlow to recognize and translate basic sign language gestures into text. It supports the following gestures:
âœ… Hello 
âœ… Bye 
âœ… I Love You 
âœ… Thank You 
âœ… Yes 
âœ… No 

âœ¨ Features
 Real-time hand tracking using MediaPipe Hands
 Gesture classification with a trained neural network
 Live text output for recognized gestures
 Custom dataset collection for sign language training
 User-friendly interface with OpenCV



 ğŸ“‚ Project Structure
data_collection.py â†’ Collects hand gesture data & saves it as CSV

train.py â†’ Trains a gesture classification model

predict.py â†’ Runs real-time sign language detection

sign_language_data.csv â†’ Dataset for training

ğŸš€ How to Run
1ï¸) Install dependencies:
sh
Copy
Edit
pip install -r requirements.txt

2ï¸) Collect gesture data (if needed):
sh
Copy
Edit
python data_collection.py

3ï¸) Train the model:
sh
Copy
Edit
python train.py

4ï¸) Run real-time interpreter:
sh
Copy
Edit
python predict.py


ğŸ“Œ Technologies Used
Python 
OpenCV 
MediaPipe 
TensorFlow/Keras 
NumPy & Pandas 
